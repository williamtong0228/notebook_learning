{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import os.path as ospath\n",
    "from os import listdir, scandir\n",
    "from os.path import isfile, join, exists\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torchdata\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import Compose,ToTensor, ToPILImage, Resize,Normalize\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scale_factor = 8\n",
    "mysize = 512\n",
    "mysize -= mysize%scale_factor\n",
    "\n",
    "EPOCH = 100\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDatasetFromPath(Dataset):\n",
    "    def __init__(self, data_path, scale_factor):\n",
    "        super(TrainDatasetFromPath,self).__init__()\n",
    "        self.image_list = make_datapath_list(train_data_path)\n",
    "        self.hd_transformer = HDTransformer(mysize,mean,std)\n",
    "        self.ld_transformer = LDTransformer(mysize, scale_factor)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_list[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        hd_transformed = self.hd_transformer(image)\n",
    "        ld_transformed = self.ld_transformer(hd_transformed)\n",
    "        \n",
    "        return ld_transformed, hd_transformed\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDatasetFromPath(Dataset):\n",
    "    def __init__(self,data_path,scale_factor):\n",
    "        super(ValDatasetFromPath, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.image_list = make_datapath_list(val_data_path)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        hd_data = Image.open(self.image_list[index]).convert('RGB')\n",
    "        w, h = hd_data.size\n",
    "        w -= w%self.scale_factor\n",
    "        h -= h%self.scale_factor\n",
    "        \n",
    "        ld_scaler = Resize((mysize//scale_factor,mysize//scale_factor), interpolation=Image.BICUBIC)\n",
    "        hd_scaler = Resize((mysize,mysize),interpolation=Image.BICUBIC)\n",
    "        hd_data = hd_scaler(hd_data)\n",
    "        ld_data = ld_scaler(hd_data)\n",
    "        hd_restored = hd_scaler(ld_data)\n",
    "#         print('ld_data {}/hd_data {}/restore_data {}'.format(ld_data.size, hd_data.size,hd_restored.size))\n",
    "        return ToTensor()(ld_data),ToTensor()(hd_restored), ToTensor()(hd_data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wa = Image.open(val_data_path + '/wa.png').convert('RGB')\n",
    "\n",
    "#  wa_scaler = Resize((mysize,mysize),interpolation=Image.BICUBIC)\n",
    "# wa_data =wa_scaler(wa)    \n",
    "# print(wa_data)\n",
    "# wa_loader = DataLoader(dataset=wa_data, num_workers=0, batch_size=1, shuffle=True)\n",
    "# wa_sr = G(wa_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDatasetFromPath(Dataset):\n",
    "    def __init__(self, data_path, scale_factor):\n",
    "        super(TestDatasetFromPath,self).__init__()\n",
    "        self.ld_path = data_path +'SR_' + str(scale_factor) + '/data/'\n",
    "        self.hd_path = data_path + 'SR_' + str(scale_factor) + '/target/'\n",
    "        self.scale_factor = scale_factor\n",
    "        self.ld_list = [join(self.ld_path,x) for x in listdir(self.ld_path)]\n",
    "        self.hd_list = [join(self.hd_path,x) for x in listdir(self.hd_path)]\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        image_name = self.ld_list[index].split('/')[-1]\n",
    "        \n",
    "        ld_data = Image.open(self.ld_list[index]).convert('RGB')\n",
    "        w, h  = ld_data.size\n",
    "        w -= w%self.scale_factor\n",
    "        h -= h%self.scale_factor\n",
    "        hd_scaler = Resize((self.scale_factor * mysize, self.scale_factor * mysize), interpolation=Image.BICUBIC)\n",
    "        hd_restored = hd_scaler(ld_data)\n",
    "        \n",
    "        return image_name, ToTensor()(ld_data), ToTensor()(hd_restored), ToTensor()(hd_data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ld_list)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayTransformer():\n",
    "    def __init__(self):\n",
    "        super(DisplayTransformer,self).__init__()\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((mysize,mysize)),\n",
    "            transforms.ToTensor(),\n",
    "        \n",
    "        ])\n",
    "        \n",
    "    def __call__(self,img):\n",
    "        return self.data_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDTransformer():\n",
    "    def __init__(self,mysize,mean,std):\n",
    "        super(HDTransformer,self).__init__()\n",
    "        self.hd_transform = Compose([\n",
    "#             ToPILImage(), #need nparray\n",
    "            Resize((mysize,mysize)),\n",
    "            ToTensor(),\n",
    "            Normalize(mean,std)\n",
    "        ])\n",
    "    def __call__(self, img):\n",
    "        return self.hd_transform(img)\n",
    "\n",
    "class LDTransformer():\n",
    "\n",
    "    def __init__(self,mysize, scale_factor):\n",
    "        super(LDTransformer,self).__init__()\n",
    "        self.ld_transform = Compose([\n",
    "            ToPILImage(),\n",
    "#             Resize((mysize//scale_factor,mysize//scale_factor), interpolation=Image.BICUBIC),\n",
    "            Resize((mysize//scale_factor,mysize//scale_factor), interpolation=Image.BICUBIC),\n",
    "            ToTensor()\n",
    "        ])\n",
    "    def __call__(self, img):\n",
    "        return self.ld_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.conv2d_2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        residual = self.conv2d_1(x)\n",
    "        residual = self.batch_norm1(residual)\n",
    "        residual = self.prelu(residual)\n",
    "        residual = self.conv2d_2(residual)\n",
    "        residual = self.batch_norm2(residual)\n",
    "        \n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self,in_channels, up_scale):\n",
    "        super(UpsampleBlock, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels, in_channels * up_scale**2, kernel_size=3, padding=1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
    "        self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        x = self.prelu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,scale_factor):\n",
    "        upsample_block_num = int(math.log(scale_factor,2))\n",
    "        \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.layer2 = ResidualBlock(64)\n",
    "        self.layer3 = ResidualBlock(64)\n",
    "        self.layer4 = ResidualBlock(64)\n",
    "        self.layer5 = ResidualBlock(64)\n",
    "        self.layer6 = ResidualBlock(64)\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64))\n",
    "        \n",
    "        layer8 = [UpsampleBlock(64,2) for _ in range(upsample_block_num)]\n",
    "        layer8.append(nn.Conv2d(64,3, kernel_size=9, padding=4))\n",
    "        self.layer8 = nn.Sequential(*layer8)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        layer1=self.layer1(x)\n",
    "        layer2=self.layer2(layer1)\n",
    "        layer3=self.layer3(layer2)\n",
    "        layer4=self.layer4(layer3)\n",
    "        layer5=self.layer5(layer4)\n",
    "        layer6=self.layer6(layer5)\n",
    "        layer7=self.layer7(layer6)\n",
    "        layer8=self.layer8(layer1 + layer7)\n",
    "        \n",
    "        \n",
    "        return (torch.tanh(layer8) + 1) /2\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllSeeingEye(nn.Module):\n",
    "    def __init__(self,z_dim=20,image_size=mysize):\n",
    "        super(AllSeeingEye,self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(512, 1024, kernel_size=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(1024, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        return torch.sigmoid(self.net(x).view(batch_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(data_path):\n",
    "    setpath = data_path\n",
    "    imgpath = os.path.join(setpath,'*.png')\n",
    "    \n",
    "#     print(imgpath)\n",
    "    path_list =[]\n",
    "    \n",
    "    for path in glob.glob(imgpath):\n",
    "#         print(path)\n",
    "        path_list.append(path)\n",
    "#     print(path_list)\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TVLoss(nn.Module):\n",
    "    def __init__(self,tv_loss_weight=1):\n",
    "        super(TVLoss,self).__init__()\n",
    "        self.tv_loss_weight = tv_loss_weight\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        \n",
    "        count_h = self.tensor_size(x[:,:,1:,:])\n",
    "        count_w = self.tensor_size(x[:,:,:,1:])\n",
    "        h_tv = torch.pow((x[:,:,1:,:] - x[:,:,:h_x - 1,:]), 2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:, 1:] - x[:,:,:, :w_x - 1]),2).sum()\n",
    "        \n",
    "        return self.tv_loss_weight * 2 * (h_tv/count_h + w_tv/ count_w)/batch_size\n",
    "    \n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size()[1]*t.size()[2]*t.size()[3]\n",
    "\n",
    "class GeneratorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorLoss,self).__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.tv_loss = TVLoss()\n",
    "        \n",
    "    \n",
    "    def forward(self, out_labels, out_images, target_images):\n",
    "        #adversarial loss\n",
    "        adversarial_loss = torch.mean(1-out_labels)\n",
    "        #perception_loss\n",
    "        #perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
    "        #Image Loss\n",
    "        image_loss = self.mse_loss(out_images, target_images)\n",
    "        \n",
    "        tv_loss = self.tv_loss(out_images)\n",
    "        \n",
    "        return image_loss + 0.001 * adversarial_loss + 2e-8 * tv_loss # + 0.006 * perception_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from math import exp\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x- window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def ssim_conv(img1, img2, window, window_size, channel, size_average=True):\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size//2,groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=channel)\n",
    "    \n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "    \n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size//2,groups=channel) -mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size//2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding=window_size//2, groups=channel) -mu1_mu2\n",
    "    \n",
    "    C1 = 0.01 **2\n",
    "    C2 = 0.03 **2\n",
    "    \n",
    "    ssim_map = ((2*mu1_mu2 + C1) * (2*sigma12 + C2))/((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "    \n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "    \n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size,self.channel)\n",
    "        \n",
    "    def forward(self,img1, img2):\n",
    "        (_, channel, _,_) =img1.size()\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            img1.to(device)\n",
    "            window.to(device)\n",
    "            window = window.type_as(img1)\n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "            \n",
    "        return ssim_conv(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "    \n",
    "def ssim(img1, img2, window_size=11,size_average=True):\n",
    "    (_, channel,_,_) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    img1.to(device)\n",
    "    window.to(device)\n",
    "    \n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return ssim_conv(img1, img2, window, window_size, channel, size_average)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mean = (0.5,)\n",
    "std = (0.5,)\n",
    "\n",
    "train_data_path = os.path.join(os.path.expanduser('~'),'downloads','trainsource')\n",
    "val_data_path = os.path.join(os.path.expanduser('~'),'downloads','testsource')\n",
    "out_path = os.path.join(os.path.expanduser('~'),'downloads','trainingresults')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "G = Generator(scale_factor)\n",
    "D = AllSeeingEye()\n",
    "G = G.to(device)\n",
    "D = D.to(device)\n",
    "train_set = TrainDatasetFromPath(train_data_path,scale_factor=scale_factor)\n",
    "val_set = ValDatasetFromPath(val_data_path,scale_factor=scale_factor)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, num_workers=0, batch_size=batch_size, shuffle=True)\n",
    "# train_loader = DataLoader(dataset=train_set,batch_size=batch_size, shuffle=True)\n",
    "# batch_iterator = iter(train_loader)\n",
    "# images = next(batch_iterator)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_set, num_workers=0, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set.image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = Generator(z_dim=20, image_size=36)\n",
    "criterion = GeneratorLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_g = optim.Adam(G.parameters())\n",
    "optimizer_d = optim.Adam(D.parameters())\n",
    "results={'d_loss':[],'g_loss':[],'d_score':[], 'g_score':[],'psnr':[],'ssim':[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader.dataset.image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weigh():\n",
    "    g_model_path = os.path.join(os.path.expanduser('~'),'onedrive\\\\g_srgan_model.pth')\n",
    "    d_model_path = os.path.join(os.path.expanduser('~'),'onedrive\\\\d_srgan_model.pth')\n",
    "    d_weights = torch.load(d_model_path)\n",
    "    g_weights = torch.load(g_model_path)\n",
    "    # d_weights = torch.load(d_model_path,map_location=torch.device('cpu'))\n",
    "    # g_weights = torch.load(g_model_path,map_location=torch.device('cpu'))\n",
    "    D.load_state_dict(d_weights)\n",
    "    G.load_state_dict(g_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.path.expanduser('~'),'downloads', \"epochs\")):\n",
    "     os.makedirs(os.path.join(os.path.expanduser('~'),'downloads', \"epochs\"))\n",
    "if not os.path.exists(os.path.join(os.path.expanduser('~'),'downloads', \"statistics\")):\n",
    "     os.makedirs(os.path.join(os.path.expanduser('~'),'downloads', \"statistics\"))\n",
    "if not os.path.exists(os.path.join(os.path.expanduser('~'),'downloads', \"checkimg\")):\n",
    "     os.makedirs(os.path.join(os.path.expanduser('~'),'downloads', \"checkimg\"))\n",
    "        \n",
    "stats_path = os.path.join(os.path.expanduser('~'),'downloads', \"statistics\")\n",
    "trained_path = os.path.join(os.path.expanduser('~'),'downloads', \"epochs\")\n",
    "checkimg_path = os.path.join(os.path.expanduser('~'),'downloads', \"checkimg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weigh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "for epoch in range(1,EPOCH + 1):\n",
    "    train_bar = tqdm(train_loader)\n",
    "    running_results = {'batch_sizes':0,'d_loss':0,'g_loss':0,'d_score':0, 'g_score':0}\n",
    "    G.train()\n",
    "    D.train()\n",
    "    for data, target in train_bar:\n",
    "        g_update_first = True\n",
    "        batch_size = data.size(0)\n",
    "        running_results['batch_sizes'] += batch_size\n",
    "\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize D(x)-1-D(G(z))\n",
    "        ###########################\n",
    "#         print('running_results')\n",
    "       \n",
    "        real_img = Variable(target).to(device)\n",
    "        z = Variable(data).to(device)\n",
    "#         print('G(z) ')\n",
    "        fake_img = G(z)\n",
    "        D.zero_grad()\n",
    "\n",
    "#         print('output real fake')\n",
    "        real_out = D(real_img).mean()\n",
    "        fake_out = D(fake_img).mean()\n",
    "        d_loss = 1 - real_out + fake_out\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        optimizer_d.step()\n",
    "\n",
    "\n",
    "        ############################\n",
    "#         (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
    "        ###########################\n",
    "\n",
    "        G.zero_grad()\n",
    "        g_loss = criterion(fake_out, fake_img, real_img)\n",
    "        g_loss.backward()\n",
    "#         print('G.zero_grad')\n",
    "#         g_loss = criterion(fake_out, fake_img, real_img)\n",
    "        fake_img = G(z).to(device)\n",
    "        fake_out = D(fake_img).mean()\n",
    "\n",
    "        optimizer_g.step()\n",
    "        running_results['d_loss'] += d_loss.item() * batch_size\n",
    "        running_results['g_loss'] += g_loss.item() * batch_size\n",
    "        running_results['d_score'] += real_out.item() * batch_size\n",
    "        running_results['g_score'] += fake_out.item() * batch_size\n",
    "#         print('running_results ',running_results)\n",
    "        train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' %(\n",
    "            epoch, EPOCH, \n",
    "            running_results['d_loss']/ running_results['batch_sizes'],\n",
    "            running_results['g_loss'] / running_results['batch_sizes'],\n",
    "            running_results['d_score'] / running_results['batch_sizes'],\n",
    "            running_results['g_score'] / running_results['batch_sizes']))\n",
    "\n",
    "    G.eval()\n",
    "    out_path_fin = out_path + str(scale_factor) + '/'\n",
    "    if not os.path.exists(out_path_fin):\n",
    "        os.makedirs(out_path_fin)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader)\n",
    "        val_check_results = {'mse':0,'ssims':0,'psnr':0,'ssim':0,'batch_sizes':0}\n",
    "        val_images = []\n",
    "#         print('val_images:{}'.format(len(val_images)))\n",
    "\n",
    "\n",
    "        for val_ld, val_hd_restore, val_hd in val_bar:\n",
    "#             print('in val_bar')\n",
    "            batch_size = val_ld.size(0)\n",
    "            val_check_results['batch_sizes'] += batch_size\n",
    "\n",
    "            ld = val_ld\n",
    "            hd = val_hd\n",
    "\n",
    "            ld = ld.to(device)\n",
    "            hd = hd.to(device)\n",
    "            \n",
    "            sr = G(ld)\n",
    "\n",
    "#             print(ld.size())\n",
    "#             print(sr.size())\n",
    "#             print(hd.size())\n",
    "\n",
    "            batch_mse = ((sr - hd)**2).data.mean()\n",
    "            val_check_results['mse'] += batch_mse * batch_size\n",
    "            batch_ssim = ssim(sr, hd).item()\n",
    "            val_check_results['ssims'] += batch_ssim * batch_size\n",
    "            val_check_results['psnr'] = 10*math.log10(1/(val_check_results['mse']/val_check_results['batch_sizes']))\n",
    "            val_check_results['ssim'] = val_check_results['ssims']/val_check_results['batch_sizes']\n",
    "            val_bar.set_description(\n",
    "                desc='[converting LD images to SR images] PSNR:%.4f dB SSIM: %.4f'%(\n",
    "                    val_check_results['psnr'],val_check_results['ssim']))\n",
    "#             print(val_hd_restore[:1,:,:,:].size())\n",
    "#             print(val_hd_restore[:1,:,:,:].squeeze(0).size())\n",
    "            val_images.extend(\n",
    "                [DisplayTransformer()(val_hd_restore[:1,:,:,:].squeeze(0)), \n",
    "                 DisplayTransformer()(hd.data[:1,:,:,:].cpu().squeeze(0)),\n",
    "                 DisplayTransformer()(sr.data[:1,:,:,:].cpu().squeeze(0))])\n",
    "#         print('exit for loop')\n",
    "        val_images = torch.stack(val_images)\n",
    "        val_images = torch.chunk(val_images, val_images.size(0)//15)\n",
    "        val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
    "        index = 1\n",
    "\n",
    "        for image in val_save_bar:\n",
    "            image = torchvision.utils.make_grid(image,nrow=3, padding = 5)\n",
    "            torchvision.utils.save_image(image, checkimg_path + '/epoch_%d_index_%d.png'%(epoch, index), padding= 5)\n",
    "            index += 1\n",
    "            \n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        \n",
    "        torch.save(G.state_dict(), trained_path + '/G_epoch_%d_%d.pth'%(scale_factor, epoch))\n",
    "        torch.save(D.state_dict(), trained_path + '/D_epoch_%d_%d.pth'%(scale_factor, epoch))\n",
    "    \n",
    "    results['d_loss'].append(running_results['d_loss']/running_results['batch_sizes'])\n",
    "    results['g_loss'].append(running_results['g_loss']/running_results['batch_sizes'])\n",
    "    results['d_score'].append(running_results['d_score']/running_results['batch_sizes'])\n",
    "    results['g_score'].append(running_results['g_score']/running_results['batch_sizes'])\n",
    "    results['psnr'].append(val_check_results['psnr'])\n",
    "    results['ssim'].append(val_check_results['ssim'])\n",
    "    \n",
    "    if epoch % 100 == 0 and epoch != 0:\n",
    "        t = time.localtime()\n",
    "        timestamp = time.strftime('%H%M%S', t)\n",
    "        data_frame = pd.DataFrame(\n",
    "            data={'Loss_D':results['d_loss'],'Loss_G':results['g_loss'],\n",
    "                  'Score_D':results['d_score'],'Score_G':results['g_score'],\n",
    "                 'PSNR':results['psnr'],'SSIM':results['ssim']},index=range(1,epoch+1))\n",
    "        data_frame.to_csv(stats_path + '/srf_' + str(scale_factor) + timestamp +  '_train_results.csv', index_label='Epoch')\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model_path = os.path.join(os.path.expanduser('~'),'onedrive\\\\g_srgan_model.pth')\n",
    "d_model_path = os.path.join(os.path.expanduser('~'),'onedrive\\\\d_srgan_model.pth')\n",
    "torch.save(D.state_dict(),d_model_path)\n",
    "torch.save(G.state_dict(),g_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname=m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_channel = 3\n",
    "exp_height = 80\n",
    "exp_width = 80\n",
    "exp_small_batchsiz = 1\n",
    "exp_path = os.path.join(os.path.expanduser('~'),'downloads\\\\onnx_srgan80.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(exp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# exp_model = Generator(scale_factor).to(device)\n",
    "\n",
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "exp_g_weights =  torch.load(g_model_path)\n",
    "G.load_state_dict(exp_g_weights)\n",
    "\n",
    "dummy_input = torch.randn(exp_small_batchsiz, exp_channel, exp_height, exp_width).to(device)\n",
    "torch.onnx.export(G, dummy_input, exp_path,export_params=True, verbose=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting torchscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traced_script_module = torch.jit.trace(model, (captions, cap_lens, hidden), check_trace=False)\n",
    "\n",
    "\n",
    "example = torch.rand(1, 3, 80, 80).to(device)\n",
    "traced_script_module = torch.jit.trace(G, example,check_trace=False).to(device)\n",
    "traced_script_module.save(os.path.join(os.path.expanduser('~'),\"srgan_80.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
